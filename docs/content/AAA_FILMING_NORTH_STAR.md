# Adult AI Academy — Filming North Star

**Course:** AI Literacy Foundations  
**Target:** Gen X adults, ~8th grade reading level, plain-English  
**Format:** Teleprompter-ready outlines for each lesson. Expand bullets into your own words; keep it conversational.

---

## Module 1: What AI Is (And Isn’t)

*Plain-English foundations so you can talk about and judge AI with confidence.*

---

### Lesson 1.1: What we mean when we say "AI"  
**Target: ~6 min**

**Opening:**
- When people say "AI," they usually mean software that can understand language, answer questions, summarize text, or generate new text or images.
- These tools are not minds. They don’t "know" things the way you do. They predict the next best word or phrase based on huge amounts of data they were trained on.

**Key points:**
- AI = very capable pattern-matching and generation tools. Useful, but not magic.
- Once you see it as a tool, not a mind, you can judge when to trust it and when to double-check.
- You don’t have to understand AI in the abstract. You can learn one use case at a time.

**Close:**
- You decide what to use, when, and with what data. That’s what AI literacy is.

---

### Lesson 1.2: How tools like ChatGPT actually work  
**Target: ~8 min**

**Opening:**
- Tools like ChatGPT, Claude, and Copilot are built on large language models (LLMs).
- Think of them as systems that predict the next best word, given everything that came before.

**Key points:**
- They were trained on massive amounts of text from the internet and books. They learned patterns, not facts.
- They can sound confident and still be wrong. That’s why we say: trust, but verify.
- The "Jagged Frontier": AI is uneven. It can handle some hard tasks and fail on easy ones. Your job is to know where the edge is.

**Analogy:**
- Treat AI like a smart but inexperienced intern. Great for drafts and ideas. Not great for final decisions without you checking.

**Close:**
- Understanding this helps you use AI without being fooled by it.

---

### Lesson 1.3: When to trust—and when to verify  
**Target: ~7 min**

**Opening:**
- AI can be wrong in two big ways: making things up, or citing a real source that doesn’t actually support the claim.
- "Hallucination" = making things up. "Misgrounding" = citing a real source that doesn’t back the claim. Misgrounding is sneakier and more dangerous.

**Key points:**
- Stanford study: some legal AI tools got 17–33% wrong. Not because they’re bad—because they’re pattern-matching, not fact-checking.
- Mata v. Avianca: lawyers filed a brief with fake citations. The AI invented them. The court caught it. Don’t be that person.
- Rule: For anything high-stakes—legal, medical, financial, HR—always verify before you use it.

**Analogy:**
- "Crumple zones": design your workflow so if the AI fails, it crashes into a human reviewer before it reaches the client or boss.

**Close:**
- When in doubt, double-check. Your reputation is worth more than five minutes of saved time.

---

## Module 2: Privacy and Safety in Everyday Use

*Protecting your data and your organization when using AI.*

---

### Lesson 2.1: Where your data goes with free vs paid tools  
**Target: ~6 min**

**Opening:**
- Free AI tools often use your prompts to train their models. Your data could end up in the next version of the product—or in someone else’s output.
- Paid or enterprise tools usually have stronger privacy protections. Your data stays in your lane.

**Key points:**
- "Walled Garden" vs "Public Park": Enterprise ChatGPT or private instances = walled garden. Free tools = public park. Know which one you’re in.
- Read the terms. Boring but important. Look for: training on your data, retention, who can see it.
- If it’s sensitive—student data, health info, client names—don’t put it in a free tool.

**Close:**
- When in doubt, assume it’s not private. Upgrade or skip.

---

### Lesson 2.2: Prompts and PII: what not to put in  
**Target: ~7 min**

**Opening:**
- PII = personally identifiable information. Names, emails, SSNs, addresses, student IDs, medical info.
- If you wouldn’t paste it in a public forum, don’t put it in a free AI tool.

**Key points:**
- Even "anonymized" data can sometimes be re-identified. Be cautious.
- Use placeholders when you’re testing: "John Doe," "example@email.com," "Student ID 12345."
- For work: if your org has approved tools, use those. "Shadow AI"—using unapproved tools in secret—creates hidden risk.

**Close:**
- Protect yourself and your organization. When in doubt, leave it out.

---

### Lesson 2.3: Simple safety habits that stick  
**Target: ~5 min**

**Opening:**
- You don’t need a compliance department. You need a few habits that become automatic.

**Key points:**
- Habit 1: Before you paste, ask—"Is this sensitive?" If yes, use a walled garden or skip.
- Habit 2: Don’t use AI for final decisions on high-stakes stuff. Draft with AI; decide with your brain.
- Habit 3: When AI gives you a citation or a stat, verify it. One quick search can save you from a big mistake.

**Close:**
- Three habits. Easy to remember. Hard to regret.

---

## Module 3: Using AI Responsibly at Work

*Practical do’s and don’ts for writing, research, and productivity.*

---

### Lesson 3.1: One prompt structure that changes the game  
**Target: ~8 min**

**Opening:**
- Bad prompts get bad answers. Good prompts get useful drafts you can refine.
- Here’s a structure that works: Role, Task, Context, Format.

**Key points:**
- Role: "You are a helpful editor" or "You are a research assistant." Sets the tone.
- Task: "Summarize this in three bullets" or "Draft a professional email that says X." Be specific.
- Context: "The audience is my boss" or "This is for a grant application." Helps the AI match your situation.
- Format: "Use bullet points" or "Keep it under 200 words." Controls the output.

**Example:**
- "You are a helpful editor. Revise this paragraph to be clearer and more concise. The audience is a busy executive. Use short sentences and bullet points if helpful."

**Close:**
- Try it. You’ll notice the difference immediately.

---

### Lesson 3.2: Evaluating outputs: bias and accuracy  
**Target: ~7 min**

**Opening:**
- AI can be biased. It learned from the internet, and the internet has biases. It can also be wrong. Your job is to catch both.

**Key points:**
- Bias: Does the output assume something about gender, race, age, or culture? Would it offend or misrepresent someone? Read it with fresh eyes.
- Accuracy: Does it cite real sources? Do those sources actually say what the AI claims? Check the links.
- If you’re not sure, get a second opinion. Human-in-the-loop means you’re the loop.

**Close:**
- Don’t publish or send until you’ve verified. Your name is on it.

---

### Lesson 3.3: Staying in control when the tool gets it wrong  
**Target: ~6 min**

**Opening:**
- AI will make mistakes. The goal isn’t perfection. It’s designing your process so mistakes don’t reach the outside world.

**Key points:**
- Build checkpoints. Draft → review → revise → send. Never skip the review.
- If the output is weird or wrong, refine the prompt. Sometimes the AI misunderstood. Sometimes you asked the wrong way.
- "Prompt debt": If your prompts are super complex and break when the model updates, simplify. Keep prompts maintainable.

**Analogy:**
- Crumple zones again. When the AI crashes, it should crash into you, not your client.

**Close:**
- You’re in charge. The tool is an assistant. Act like it.

---

## Module 4: Next Steps: Tools and Governance

*Choosing tools, vetting vendors, and simple governance without a compliance department.*

---

### Lesson 4.1: How to vet an AI tool in 10 minutes  
**Target: ~8 min**

**Opening:**
- You don’t need a 50-page rubric. You need a short checklist you can run through before you or your team adopt a new tool.

**Key points:**
- Question 1: What data does it collect, and where does it go? Check the privacy policy.
- Question 2: Does it use my data to train its model? If yes, and you have sensitive data, skip or use enterprise.
- Question 3: Is it accessible? Can people with disabilities use it? WCAG matters.
- Question 4: What happens when I delete my account? Do they actually delete my data? Look for data destruction or retention terms.

**Close:**
- Ten minutes. Four questions. Could save you from a nightmare.

---

### Lesson 4.2: FERPA/COPPA in plain English (for educators)  
**Target: ~7 min**

**Opening:**
- If you work with students, you’ve heard FERPA and COPPA. Here’s the short version.

**Key points:**
- FERPA: Protects student education records. Generally, you need parent consent before sharing identifiable student data with a third party—including an AI vendor.
- COPPA: Protects kids under 13 online. AI tools that collect data from children have strict rules. Many free tools are not COPPA-compliant for classroom use.
- Bottom line: Don’t put student names, IDs, or identifiable info into a tool unless you’ve verified it’s compliant and your district approves it.

**Close:**
- When in doubt, ask your district. Protect the kids.

---

### Lesson 4.3: Building a minimal use policy  
**Target: ~6 min**

**Opening:**
- You don’t need a 20-page policy. You need one page that answers: Who can use what, for what, with what data?

**Key points:**
- What’s allowed: Which tools are approved? For what tasks?
- What’s not allowed: No student PII in unapproved tools. No final high-stakes decisions without human review.
- Who decides: One person or a small team approves new tools. Everyone else uses the approved list.

**Close:**
- Simple. Clear. Easy to follow. That’s good governance.

---

## Quick Reference: Plain-English Terms to Use

| Term | Use it when |
|------|-------------|
| **Drunk Intern** | Explaining why AI needs supervision |
| **Walled Garden** | Enterprise/private tools vs. free public ones |
| **Hallucination** | AI making things up |
| **Misgrounding** | AI citing a real source that doesn’t support the claim |
| **Crumple Zones** | Human checkpoints in your workflow |
| **Shadow AI** | Employees using unapproved tools |
| **Human-in-the-loop** | Humans verify before AI output goes live |
| **Jagged Frontier** | AI is uneven—good at some things, bad at others |

---

## Filming Notes

- **Tone:** Conversational, supportive. You’re the guide, not the lecturer.
- **Pace:** ~150 words/min for teleprompter. Adjust for emphasis and pauses.
- **Energy:** Steady, confident. Gen X responds to "I’ve been there" energy.
- **Length:** Target durations are suggestions. Better to be clear and slightly long than rushed.
