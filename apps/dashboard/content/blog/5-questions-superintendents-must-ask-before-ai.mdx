---
title: "The 5 Questions Every Superintendent Must Ask Before Adopting AI Tools"
date: "2026-02-10"
excerpt: "AI tools are flooding into classrooms. Before you sign a contract, make sure you can answer these five questions — or you could be opening your district to compliance risk and parent backlash."
author: "John Lyman"
tags: ["AI governance", "K-12", "superintendent", "FERPA", "COPPA", "vendor vetting"]
---

A superintendent forwarded me a demo last week. An edtech vendor had just added an AI feature to their platform — automated feedback on student writing, personalized reading recommendations, the usual promises. The question was simple: *Should we pilot this?*

My response: *Ask these five questions first.*

Every week, another vendor rolls out AI capabilities. The pressure to adopt is real. But the districts that thrive aren't the ones that move fastest. They're the ones that move *deliberately*. Before you sign a pilot agreement, board approval, or purchase order, make sure you can answer the following — and document the answers.

## 1. Does This Tool Comply with FERPA and COPPA?

This isn't optional. FERPA protects education records. COPPA protects children under 13 online. Most AI tools that process student data trigger one or both.

**What to ask the vendor:** Where does our data go? Is it used to train their model? Do they have a Data Privacy Agreement (DPA) or Student Data Privacy Agreement? Are they aligned with the Student Data Privacy Consortium (SDPC) framework?

**Red flags:** "We use industry-standard security." "We're compliant." Vague answers. No written DPA. If they can't produce a clear, signed agreement that specifies how student data is handled, stored, and retained — and whether it's used for model training — don't move forward.

**Green lights:** SDPC-aligned vendor, explicit DPA, documented compliance with FERPA and COPPA.

## 2. Who Owns the Student Data Generated by the AI?

When a student uses an AI writing assistant, who owns the outputs? The prompts? The metadata about how the tool was used?

**What to ask:** Does the vendor claim ownership of any student-generated content or usage data? Can the district export and delete all student data upon request? What happens when the contract ends?

**Red flags:** Vendor claims ownership of aggregated or anonymized data derived from student use. Unclear data deletion procedures.

**Green lights:** District retains full ownership. Vendor provides data export and deletion within a defined timeframe (e.g., 30 days of contract termination).

## 3. Can We Audit and Explain AI Decisions to Parents?

When a parent asks, "Why did this tool recommend that for my child?" — can you answer?

**What to ask:** Does the vendor provide transparency into how the AI makes decisions? Can you explain to a parent *why* a recommendation was made? Is there an audit trail?

**Red flags:** Black-box AI. "Proprietary algorithm." No explainability.

**Green lights:** Vendor provides documentation on how recommendations are generated. Audit logs available. Human review or override options for high-stakes decisions.

## 4. Does Our Board Policy Cover AI Use?

Many districts have acceptable use policies written before ChatGPT existed. Do yours cover AI?

**What to ask:** Does your current AUP or technology policy explicitly address AI tools? Who is authorized to adopt new AI applications? What's the process — principal approval? Tech director? Board vote?

**Red flags:** No policy. Policy is silent on AI. Adoption happens ad hoc.

**Green lights:** Board-adopted AI use policy. Clear governance: who can use what, for what purposes, with what data. Procurement process includes AI-specific vetting.

## 5. How Do We Train Staff on Responsible Use Before Rollout?

The best policy in the world fails if no one knows it exists.

**What to ask:** Do we have role-specific training — for teachers, counselors, admins — before we deploy? Who delivers it? How do we measure that staff understand the boundaries?

**Red flags:** "We'll do a quick training." "Teachers are tech-savvy, they'll figure it out."

**Green lights:** Structured training aligned with policy. Scenarios: "A student asks you to use ChatGPT on an assignment — what do you say?" Documentation that training was completed.

---

## Your Next Step

These five questions aren't meant to slow you down. They're meant to protect your district, your students, and your community. The vendors who can answer them clearly are the ones worth piloting.

[Book a free 15-minute Cognitive Audit call](/contact) to assess your district's AI readiness, or [take the AI Readiness Quiz](/tools/ai-readiness-quiz) to see where you stand.
